{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ End-to-end tutorial for WSI processing and benchmarking\n",
    "\n",
    "Follow along this tutorial to download WSIs, process them with Trident, and run benchmarking studies using Patho-Bench.\n",
    "\n",
    "## What will this tutorial cover?\n",
    "1. Downloading WSIs for CPTAC Clear Cell Renal Cell Carcinoma (CCRCC)\n",
    "2. Processing the WSIs with [Trident](https://github.com/mahmoodlab/trident), our one-stop package for WSI preprocessing\n",
    "3. Running benchmarking studies. Following examples are included:  \n",
    "    a. Linear probe for BAP1 mutation prediction  \n",
    "    b. Cox Proportional Hazards (CoxPH) model for survival prediction    \n",
    "    c. Attention-based multiple instance learning model for BAP1 mutation prediction  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚¨áÔ∏è Download CPTAC CCRCC WSIs \n",
    "\n",
    "You can easily download CPTAC CCRCC WSIs from [TCIA Cancer Imaging Archive](https://www.cancerimagingarchive.net/collection/cptac-ccrcc/). If you have access to SSD, download your WSIs there for faster IO. \n",
    "\n",
    "**Tip**: Keep an eye out on this webpage for any new updates to the dataset as newer versions are often released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßë‚Äçüî¨ üß¨ Installing Patho-Bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run:\n",
    "\n",
    "1. `conda create -n pathobench python=3.10`\n",
    "2. `conda activate pathobench`\n",
    "3. `pip install -e .`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Preprocess WSIs: segmentation, patching and patch feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [Trident](https://github.com/mahmoodlab/trident), our package for WSI processing and feature extraction. Trident is already installed as part of Patho-Bench installation. \n",
    "\n",
    "Run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from run_batch_of_slides import main # import Trident launch script. \n",
    "\n",
    "sys.argv = [\n",
    "    \"run_batch_of_slides\",\n",
    "    '--task', 'all', \\\n",
    "    '--job_dir', './cptac_ccrcc', \\\n",
    "    '--wsi_dir', './CPTAC-CCRCC_v1/CCRCC', \\\n",
    "    '--patch_encoder', 'conch_v15', \\\n",
    "    '--mag', '20', \\\n",
    "    '--patch_size', '512', \\\n",
    "    '--skip_errors',\n",
    "]\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the following directory structure as the output. Note, we have placed the `wsis` folder inside the job dir, but you can put it anywhere.\n",
    "```bash\n",
    "|-->/path/to/job_dir\n",
    "    |-->20x_512px_0px_overlap\n",
    "        |-->features_conch_v15 --> these are the patch features\n",
    "        |-->patches\n",
    "        |-->visualizations\n",
    "    |-->contours\n",
    "    |-->contours_geojson\n",
    "    |-->thumbnails\n",
    "    |-->wsis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a linear probe experiment for BAP1 mutation prediction  \n",
    "\n",
    "For predicting BAP1 mutation in CCRCC using Titan slide embeddings, we train a linear regression model (linear probe). Below is a modular function to run a linear probe experiment. Please see docstrings for more details on specific arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from patho_bench.SplitFactory import SplitFactory\n",
    "from patho_bench.ExperimentFactory import ExperimentFactory\n",
    "\n",
    "model_name = 'titan'\n",
    "train_source = 'cptac_ccrcc' \n",
    "task_name = 'BAP1_mutation'\n",
    "\n",
    "# For this task, we will automatically download the split and task config from HuggingFace.\n",
    "path_to_split, path_to_task_config = SplitFactory.from_hf('./_tutorial_splits', train_source, task_name)\n",
    "\n",
    "# Now we can run the experiment\n",
    "experiment = ExperimentFactory.linprobe(\n",
    "                    split = path_to_split,\n",
    "                    task_config = path_to_task_config,\n",
    "                    pooled_embeddings_dir = os.path.join('./_tutorial_pooled_features', model_name, train_source, 'by_case_id'), # This task uses case-level pooling\n",
    "                    saveto = f'./_tutorial_linprobe/{train_source}/{task_name}/{model_name}',\n",
    "                    combine_slides_per_patient = False,\n",
    "                    cost = 1,\n",
    "                    balanced = False,\n",
    "                    patch_embeddings_dirs = '/media/ssd1/cptac_ccrcc/20x_512px_0px_overlap/features_conch_v15',\n",
    "                    model_name = model_name,                    \n",
    "                )\n",
    "experiment.train()\n",
    "experiment.test()\n",
    "result = experiment.report_results(metric = 'macro-ovr-auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of downloading the split and task config from Huggingface, you can also provide your own split and task config. If you wish to develop custom splits and tasks, please follow the format of the HuggingFace downloaded splits and task configs. At minimum, your task config should contain the following fields.\n",
    "\n",
    "```yaml\n",
    "task_col: BAP1_mutation # Column containing labels for the task\n",
    "extra_cols: [] # Any extra columns needed to perform the task (e.g. survival tasks)\n",
    "\n",
    "metrics: # List of one or more performance metrics to report (this is used for automated result compilation when using Patho-Bench in advanced mode)\n",
    "  - macro-ovr-auc\n",
    "\n",
    "label_dict: # Dictionary of integer labels to string labels\n",
    "  0: wildtype\n",
    "  1: mutant\n",
    "\n",
    "sample_col: case_id # Column containing the unit of analysis. Use 'case_id' for patient-level tasks and 'slide_id' for slide-level tasks.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a retrieval experiment for BAP1 mutation prediction  \n",
    "\n",
    "Same task as linear probe experiment above, but now we will use patient-level retrieval instead of a linear probe. We are using the same splits as downloaded in the cell above.\n",
    "\n",
    "If you already ran the cell above, you will already have case-level embeddings saved in `pooled_embeddings_dir`. This means you don't have to provide the `patch_embeddings_dirs` and `model_name` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from patho_bench.SplitFactory import SplitFactory\n",
    "from patho_bench.ExperimentFactory import ExperimentFactory\n",
    "\n",
    "model_name = 'titan'\n",
    "train_source = 'cptac_ccrcc' \n",
    "task_name = 'BAP1_mutation'\n",
    "\n",
    "# Now we can run the experiment\n",
    "experiment = ExperimentFactory.retrieval(\n",
    "                    split = f'./_tutorial_splits/cptac_ccrcc/{task_name}/k=all.tsv',\n",
    "                    task_config = f'./_tutorial_splits/cptac_ccrcc/{task_name}/config.yaml',\n",
    "                    pooled_embeddings_dir = os.path.join('./_tutorial_pooled_features', model_name, train_source, 'by_case_id'), # This task uses case-level pooling\n",
    "                    saveto = f'./_tutorial_retrieval/{train_source}/{task_name}/{model_name}',\n",
    "                    combine_slides_per_patient = False,\n",
    "                    similarity = 'l2',\n",
    "                    centering = False,\n",
    "                    \n",
    "                    # Don't need to provide the following args because pooled embeddings are already computed and saved to pooled_embeddings_dir\n",
    "                    # patch_embeddings_dirs = '/media/ssd1/cptac_ccrcc/20x_512px_0px_overlap/features_conch_v15',\n",
    "                    # model_name = model_name,                    \n",
    "                )\n",
    "\n",
    "experiment.train()\n",
    "experiment.test()\n",
    "result = experiment.report_results(metric = 'mAP@1')\n",
    "result = experiment.report_results(metric = 'mAP@5')\n",
    "result = experiment.report_results(metric = 'mAP@10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a survival prediction experiment for CPTAC CCRCC\n",
    "\n",
    "Let's see how can we train a CoxPH model to predict survival (`OS`) using Titan slide embeddings. For this one we'll have to download a new split from Huggingface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from patho_bench.SplitFactory import SplitFactory\n",
    "from patho_bench.ExperimentFactory import ExperimentFactory\n",
    "\n",
    "model_name = 'titan'\n",
    "train_source = 'cptac_ccrcc' \n",
    "task_name = 'OS'\n",
    "\n",
    "# For this task, we will automatically download the split and task config from HuggingFace.\n",
    "path_to_split, path_to_task_config = SplitFactory.from_hf('./_tutorial_splits', train_source, task_name)\n",
    "\n",
    "# Now we can run the experiment\n",
    "experiment = ExperimentFactory.coxnet(\n",
    "                    split = path_to_split,\n",
    "                    task_config = path_to_task_config,\n",
    "                    pooled_embeddings_dir = os.path.join('./_tutorial_pooled_features', model_name, train_source, 'by_case_id'), # This task uses case-level pooling\n",
    "                    saveto = f'./_tutorial_coxnet/{train_source}/{task_name}/{model_name}',\n",
    "                    combine_slides_per_patient = False,\n",
    "                    alpha = 0.07,\n",
    "                    l1_ratio = 0.5,\n",
    "                    \n",
    "                    # Don't need to provide the following args because pooled embeddings are already computed and saved to pooled_embeddings_dir\n",
    "                    # patch_embeddings_dirs = '/media/ssd1/cptac_ccrcc/20x_512px_0px_overlap/features_conch_v15',\n",
    "                    # model_name = model_name,                    \n",
    "                )\n",
    "experiment.train()\n",
    "experiment.test()\n",
    "result = experiment.report_results(metric = 'cindex')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üñåÔ∏è Training an ABMIL from scratch\n",
    "\n",
    "In many scenarios, a simple linear probe may not be sufficient and you need a deep learning model. `Patho-Bench` will support you in easily training attention based multiple instance learning (ABMIL) models for this purpose. Let's use our example of BAP1 mutation to train an ABMIL model. Note that running the below cell may take some time, as this task has 50 folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patho_bench.ExperimentFactory import ExperimentFactory\n",
    "\n",
    "model_name = 'abmil'\n",
    "train_source = 'cptac_ccrcc'\n",
    "task_name = 'BAP1_mutation'\n",
    "\n",
    "experiment = ExperimentFactory.finetune(\n",
    "                    split = f'./_tutorial_splits/cptac_ccrcc/{task_name}/k=all.tsv',\n",
    "                    task_config = f'./_tutorial_splits/cptac_ccrcc/{task_name}/config.yaml',\n",
    "                    patch_embeddings_dirs = '/media/ssd1/downstream_conch/cptac_ccrcc',\n",
    "                    saveto = f'./_tutorial_finetune/{train_source}/{task_name}/{model_name}',\n",
    "                    combine_slides_per_patient = False,\n",
    "                    model_name = model_name,\n",
    "                    bag_size = 2048,\n",
    "                    base_learning_rate = 0.0003,\n",
    "                    layer_decay = None, \n",
    "                    gradient_accumulation = 1,\n",
    "                    weight_decay = 0.00001,\n",
    "                    num_epochs = 20,\n",
    "                    scheduler_type = 'cosine',\n",
    "                    optimizer_type = 'AdamW',\n",
    "                    balanced = True, \n",
    "                    save_which_checkpoints = 'last-1',\n",
    "                    model_kwargs = {                    # ABMIL requires extra kwargs. Other models do not.\n",
    "                        'input_feature_dim': 768,\n",
    "                        'n_heads': 1,\n",
    "                        'head_dim': 512,\n",
    "                        'dropout': 0.25,\n",
    "                        'gated': False\n",
    "                    }\n",
    "                    )\n",
    "experiment.train()\n",
    "experiment.test()\n",
    "result = experiment.report_results(task_name, 'macro-ovr-auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `ExperimentFactory.finetune()` method can also be used for finetuning pretrained slide encoders instead of training an ABMIL from scratch. You are encouraged to read the code and explore the additional capabilities of Patho-Bench."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathobench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
