BASE_LEARNING_RATE: # Base learning rate
    - 0.002 # This yields an effective BLR of 0.00025, which matches the official implementation

WEIGHT_DECAY: # Weight decay
    - 0.05

LAYER_DECAY: # Layer-wise learning rate decay
    - 0.95

GRADIENT_ACCUMULATION: # Gradient accumulation
    - 32

NUM_EPOCHS: # Number of epochs
    - 5

SCHEDULER_TYPE: # Scheduler type
    - gigapath

OPTIMIZER_TYPE: # Optimizer type
    - gigapath

BALANCED: # Whether to use balanced loss
    - True

BAG_SIZE: # Bag size
    - null

SAVE_WHICH_CHECKPOINTS: # Method to save checkpoints
    - last-1